#!/bin/bash

#############################################
## EXPECTS THAT setup_do-once HAS BEEN RUN ##
#############################################
# where # is the topic number

echo "Judging N files START!"

topic=$1
working_files="WORKINGFILES"
directory="metadata_files"
train_file="${working_files}/train_file_$topic"
test_file="${working_files}/test_file_$topic"
test_file_ids="${working_files}/test_file_ids_$topic"
model="${working_files}/model_$topic"
results="${working_files}/results_file_$topic" # this doesn't really matter, is never used
topN_rel="${working_files}/topN_rel"
N=1 #number of files to judge before retraining the model
relevant_words_file="${working_files}/relevant_words_file_$topic"

# hyperparameters by https://dl.acm.org/doi/10.1145/2600428.2609601
iterations=2000000
dimensionality=1100000
learner_type="logreg-pegasos" #paper only says Pegasos, log-pegasos is chosen from Gordon's class
# hyperparameters by Gordon's class
loop_type="roc" #he didn't specify, we went with the one that's binary labeling
lambda=0.00001

# filter out the ones that have been judged (using jj_topic_#) and label accordingly
# and store results to train_file, the rest are stored to test_file wtih rel 0
python label_rel.py $topic $train_file $test_file $test_file_ids $working_files

# feed training_file_# to sofiaML to and obtain the model
~/sofia-ml-read-only/sofia-ml --learner_type $learner_type --loop_type $loop_type --lambda $lambda --iterations $iterations --dimensionality $dimensionality --training_file $train_file --model_out $model

# feed model and testing_file_# to sofiaML to get rel judgements
~/sofia-ml-read-only/sofia-ml --model_in $model --test_file $test_file --results_file $results

# select the top 10 most rel documents from not_judged_files_#
# according to SofiaML
# paste together file ids and their results before sorting
cut -f 1 $results > t2
paste -d ' ' t2 $test_file_ids > t3
mv t3 $results

# sort results by rel, then by conf where k1 = conf, k2 = name
# show only the top 10 to be labeled
sort -rg $results | head -n $N | cut -d ' ' -f 2 > $topN_rel

#######################################
## CHOOSING WORDS TO HIGHLIGHT start ##
#######################################
doc_to_judge=`cat $topN_rel`
~/featurekit/porteroff ${directory}/$doc_to_judge | sort > list1
cut -d ' ' -f 2 df | cat -n > list2
join -1 1 -2 2 list1 list2 > list3

cut -d ' ' -f 4 list3 > model_posns

rm list1
rm list2
rm list3

touch temp
rm temp
while read line;
do
	cut -d ' ' -f $((line+1)) $model >> temp
done < model_posns

cut -d ' ' -f 1 list3 > temp2
paste -d ' ' temp temp2 | uniq | sort -gr | grep -v "^0 " | grep -v "^-" | head -n 5 | cut -d ' ' -f 2 > $relevant_words_file # take top 5 according to Gordon

rm temp
rm temp2

#####################################
## CHOOSING WORDS TO HIGHLIGHT end ##
#####################################

# give rel judgements and save to jj_topic_#
echo "Starting human judgements!"
python displayMetadataFile.py $topN_rel $topic $directory $relevant_words_file
echo "Finished human judgements!"

# REPEAT
echo "Judging N files DONE!"